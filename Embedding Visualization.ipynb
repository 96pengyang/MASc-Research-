{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1448622d",
   "metadata": {},
   "source": [
    "# Visualize Embeddings using Pytorch version of Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94488cf",
   "metadata": {},
   "source": [
    "Things to remember when using Tensorboard in Jupyter Notebook:\n",
    "- `%tensorboard --logdir=<dir-name>` requires `<dir-name>` to be the actual string (without quotes), not variable and use the highest directory level (e.g., use **test** in **test/exp1/run1** as `<dir-name>`)\n",
    "- Assuming same `log_dir`\n",
    "    - Calling writer functions AFTER restarting notebook will override existing proj-config file\n",
    "    - Calling writer functions BEFORE restarting notebook will append existing proj-config file (Restart still required to reflect changes)\n",
    "- Not specifying `tag` or `global_step` argument when calling multiple `add_embedding` function will still work as intended, but for some reason only one sprite and tsv file appears\n",
    "- Always completely kill and delete Tensorboard processes before exiting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1025b",
   "metadata": {},
   "source": [
    "***Go to the visualization section directly if required files are already available and written to Tb***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92f0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary modules if not already (Uncomment lines below)\n",
    "# pip install tensorflow\n",
    "# pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6d2516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check tensorboard versions (Duplicated versions can result in errors)\n",
    "# import pkg_resources\n",
    "\n",
    "# for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins'):\n",
    "#     print(entry_point.dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f73653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Fixes tensorboard error with tf\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2170a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_embed_load(data_path, embed_path):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Loads the training data and embedding\n",
    "    \n",
    "    Args: \n",
    "        data_path: Path of training data file \n",
    "        embed_path: Path of embedding file \n",
    "        \n",
    "    Outputs:\n",
    "        imgs: Loaded training data (N, C, W, H)\n",
    "        embed: Loaded embedding (N, embed_dim)   \n",
    "\n",
    "    \"\"\"\n",
    "    # Load saved training file\n",
    "    print('Loading training data...')\n",
    "    train_data = torch.load(data_path) # (N, W, H, C)\n",
    "    loader = torch.utils.data.DataLoader(train_data, \n",
    "                                         batch_size = len(train_data), \n",
    "                                         shuffle = False)\n",
    "    dataiter = iter(loader)\n",
    "    imgs = dataiter.next()\n",
    "    imgs = imgs.cpu().detach().permute((0, 3, 1, 2)) / 255 # (N, C, W, H) and scale pixel values between [0, 1]\n",
    "    print('Done')\n",
    "    print('Training data shape, type, and dtype: ', imgs.shape, type(imgs), imgs.dtype)\n",
    "    print('\\n')\n",
    "    \n",
    "    # Load saved embedding file\n",
    "    print('Loading embeddings...')\n",
    "    embed = torch.load(embed_path) # (N, embed_dim)\n",
    "    if type(embed) is not np.ndarray:\n",
    "        embed = embed.cpu().detach()\n",
    "    print('Done')\n",
    "    print('Embedding shape, type, and dtype: ', embed.shape, type(embed), embed.dtype)\n",
    "    print('\\n')\n",
    "    \n",
    "    return imgs, embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08f1b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_list(embed, K_clusters):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Creates metadata required to visualize data with associated cluster class\n",
    "    \n",
    "    Args: \n",
    "        embed: Loaded embedding (N, embed_dim)   \n",
    "        K_clusters: The number of cluster classes (int)\n",
    "        \n",
    "    Outputs:\n",
    "        pred: A list containing the cluster class of each element (tile)\n",
    "\n",
    "    \"\"\"\n",
    "    print('Creating cluster metadata with {} classes...'.format(K_clusters))\n",
    "    \n",
    "    # Convert embedding to numpy array\n",
    "    if type(embed) is not np.ndarray:\n",
    "        embed = embed.cpu().detach().numpy() # (N, embed_dim)\n",
    "    \n",
    "    # Cluster the embedding\n",
    "    kmeans = KMeans(n_clusters = K_clusters, random_state = 1)\n",
    "    pred = kmeans.fit_predict(embed) # (N,)\n",
    "    pred = pred.tolist() # type list required \n",
    "    \n",
    "    print('Done')\n",
    "    print('Metadata length and type: ', len(pred), type(pred))\n",
    "    print('\\n')\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8843d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tb_add_embed(t_dir, e_dir, dim, log, K_clusters = None, all_classes = False):\n",
    "    \"\"\"\n",
    "    Description: \n",
    "        Adds data to Tensorboard\n",
    "    \n",
    "    Args: \n",
    "        t_dir: Main directory containing the training tensors\n",
    "        e_dir: Main directory containing the embeddings\n",
    "        dim: Dimension of each image tile\n",
    "        log: Path of Tensorboard log directory    \n",
    "        K_clusters: The number of cluster classes (int)\n",
    "        all_classes: Whether to create multiple K_clusters metadata all at once (bool)\n",
    "        \n",
    "    Outputs:\n",
    "        data_path: Path to the training tensor files\n",
    "        embed_path: Path to the embedding files\n",
    "        embed_name: Name of the embedding files\n",
    "\n",
    "    \"\"\"    \n",
    "        \n",
    "    data_path, embed_path, embed_name = [], [], []\n",
    "    \n",
    "    # Get name of training tensors and its directory\n",
    "    for f in os.listdir(t_dir):\n",
    "        if all( s in f for s in ['train_tensors', str(dim)] ):\n",
    "            data_path.append(os.path.join(t_dir, f))\n",
    "    \n",
    "    # Get name of embedding and its directory\n",
    "    for f in os.listdir(e_dir):\n",
    "        if f.split(\"_\")[0] == 'embed' and f.split(\"_\")[2] == ('dim' + str(dim)) and f.split(\".\")[-1] != 'tsv':               \n",
    "            embed_path.append(os.path.join(e_dir, f))\n",
    "            embed_name.append(f.split(\".\")[0])\n",
    "    \n",
    "    print('Adding embedding to Tensorboard...\\n')\n",
    "    \n",
    "    i = 1\n",
    "    writer = SummaryWriter(log_dir = log) \n",
    "    for dpath, epath, ename in zip(data_path, embed_path, embed_name):\n",
    "        # Load data\n",
    "        imgs, embed = train_embed_load(dpath, epath) \n",
    "        \n",
    "        # Tensorboard can only take sprites 8192 x 8192\n",
    "        if int(np.ceil(np.sqrt(imgs.shape[0]) * imgs.shape[-1])) > 8191:\n",
    "            print('Skipping because the number of images is too large\\n')\n",
    "            continue          \n",
    "                 \n",
    "        # Create metadata containing cluster classes and write everything to projector\n",
    "        if K_clusters is None:\n",
    "            pred = None\n",
    "            writer.add_embedding(mat = embed, \n",
    "                                 metadata = pred, \n",
    "                                 label_img = imgs, \n",
    "                                 global_step = K_clusters, \n",
    "                                 tag = ename)\n",
    "        elif K_clusters is not None and all_classes == True:\n",
    "            # Write to projector for multiple max cluster classes\n",
    "            for K in range(2, K_clusters + 1):\n",
    "                pred = create_cluster_list(embed, K)\n",
    "                writer.add_embedding(mat = embed, \n",
    "                             metadata = pred, \n",
    "                             label_img = imgs, \n",
    "                             global_step = K, \n",
    "                             tag = ename)\n",
    "        else:\n",
    "            pred = create_cluster_list(embed, K_clusters)\n",
    "            writer.add_embedding(mat = embed, \n",
    "                                 metadata = pred, \n",
    "                                 label_img = imgs, \n",
    "                                 global_step = K_clusters, \n",
    "                                 tag = ename)\n",
    "        \n",
    "        print('Added {} embedding \\n'.format(i))\n",
    "        i += 1\n",
    "    \n",
    "    writer.close()    \n",
    "    print('Embeddings all added')\n",
    "    \n",
    "    return data_path, embed_path, embed_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eba0454d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BILLYY~1\\AppData\\Local\\Temp/ipykernel_14504/3251775797.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Main directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr'D:\\MASC Big Files\\Data Processing\\Deep Learning\\Unsupervised Learning\\Bald Mountain\\Top Pit\\2021_BM_Top'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0membed_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'Model_MT_Outputs\\Embeddings\\s5555 first run'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Change paths accordingly\n",
    "# Main directory\n",
    "train_dir = r'D:\\MASC Big Files\\Data Processing\\Deep Learning\\Unsupervised Learning\\Bald Mountain\\Top Pit\\2021_BM_Top'\n",
    "embed_dir = os.path.join(train_dir, r'Model_MT_Outputs\\Embeddings\\s5555 first run')\n",
    "dim = 64\n",
    "K = 7\n",
    "write_all = True\n",
    "log_dir = 'tb_embed/MT/2021_BM_Top/' + str(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719fa50a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding embedding to Tensorboard...\n",
      "\n",
      "Loading training data...\n",
      "Done\n",
      "Training data shape, type, and dtype:  torch.Size([10736, 3, 64, 64]) <class 'torch.Tensor'> torch.float32\n",
      "\n",
      "\n",
      "Loading embeddings...\n",
      "Done\n",
      "Embedding shape, type, and dtype:  torch.Size([10736, 128]) <class 'torch.Tensor'> torch.float32\n",
      "\n",
      "\n",
      "Creating cluster metadata with 2 classes...\n",
      "Done\n",
      "Metadata length and type:  10736 <class 'list'>\n",
      "\n",
      "\n",
      "Creating cluster metadata with 3 classes...\n",
      "Done\n",
      "Metadata length and type:  10736 <class 'list'>\n",
      "\n",
      "\n",
      "Creating cluster metadata with 4 classes...\n",
      "Done\n",
      "Metadata length and type:  10736 <class 'list'>\n",
      "\n",
      "\n",
      "Creating cluster metadata with 5 classes...\n",
      "Done\n",
      "Metadata length and type:  10736 <class 'list'>\n",
      "\n",
      "\n",
      "Creating cluster metadata with 6 classes...\n",
      "Done\n",
      "Metadata length and type:  10736 <class 'list'>\n",
      "\n",
      "\n",
      "Creating cluster metadata with 7 classes...\n",
      "Done\n",
      "Metadata length and type:  10736 <class 'list'>\n",
      "\n",
      "\n",
      "Added 1 embedding \n",
      "\n",
      "Embeddings all added\n"
     ]
    }
   ],
   "source": [
    "d, e, _ = tb_add_embed(t_dir = train_dir,\n",
    "                       e_dir = embed_dir,\n",
    "                       dim = dim, \n",
    "                       log = log_dir, \n",
    "                       K_clusters = K, \n",
    "                       all_classes = write_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9620ac8",
   "metadata": {},
   "source": [
    "### Attempt: Visualize training tensors directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c892bc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thumbnail images shape:  torch.Size([2729, 3, 128, 128])\n",
      "Projected images shape:  (2729, 49152)\n"
     ]
    }
   ],
   "source": [
    "# Visualize training tensors directly\n",
    "# Import training data\n",
    "pth = r'D:\\MASC Big Files\\Data Processing\\Deep Learning\\Unsupervised Learning\\Bald Mountain\\Top Pit\\2021_BM_Top'\n",
    "train_data = torch.load(os.path.join(pth, 'train_tensors_128_sample.pt')) # torch tensor (N, W, H, C)\n",
    "loader = torch.utils.data.DataLoader(train_data, \n",
    "                                     batch_size = len(train_data), \n",
    "                                     shuffle = False)\n",
    "dataiter = iter(loader)\n",
    "imgs = dataiter.next()\n",
    "imgs = imgs.cpu().detach().permute((0, 3, 1, 2)) # torch tensor [N, C, H, W]\n",
    "\n",
    "# Create label images for thumbnails\n",
    "label_imgs = imgs / 255 # torch tensor (N, C, W, H) and scale pixel values between [0, 1]\n",
    "\n",
    "# Change training Pytorch tensors to (N, C * H * W) numpy array for K-Means clustering\n",
    "imgs = imgs.reshape(label_imgs.shape[0], -1).numpy() # np array [N, C * H * W]\n",
    "\n",
    "print('Thumbnail images shape: ', label_imgs.shape)\n",
    "print('Projected images shape: ', imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35e4b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to projector\n",
    "writer = SummaryWriter(log_dir = 'tb_training/2021_BM_Top/128') \n",
    "writer.add_embedding(mat = imgs,\n",
    "                     label_img = label_imgs                     \n",
    "                    )\n",
    "# K = 7\n",
    "# for K in range(3, K + 1):\n",
    "#     pred = create_cluster_list(imgs, K)\n",
    "#     writer.add_embedding(mat = imgs, \n",
    "#                  metadata = pred, \n",
    "#                  label_img = label_imgs, \n",
    "#                  global_step = K, \n",
    "#                  tag = str(K)) # tag needs to be a string\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d0f0d",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05673d6f",
   "metadata": {},
   "source": [
    "Click http://localhost:6006/#projector for better viewing experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0009ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tensorboard extension\n",
    "%load_ext tensorboard\n",
    "# %reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49b78cff",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5722a173523667f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5722a173523667f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remember to completely kill process\n",
    "%tensorboard --logdir=tb_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48179331",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS: The process \"tensorboard.exe\" with PID 8992 has been terminated.\n"
     ]
    }
   ],
   "source": [
    "# Kills tensorboard and removes info files (uncomment)\n",
    "!taskkill /IM \"tensorboard.exe\" /F\n",
    "!rmdir /S /Q %temp%\\.tensorboard-info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb4e6e",
   "metadata": {},
   "source": [
    "=========================================================================================================================================\n",
    "========================================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2851bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Change paths accordingly\n",
    "# # Data loading\n",
    "# fpath = r'D:\\MASC Big Files\\Code\\Deep Learning\\Gold Bar\\Pick Pit\\2019_BM_Top'\n",
    "# data_file = r'\\train_tensors_2_128.pt'\n",
    "\n",
    "# # Project config file\n",
    "# embed_file = '\\Model_MT_Outputs\\embed_MT_dim128_emb128_2.tsv'\n",
    "# sprite_file = '\\Model_MT_Outputs\\sprite.jpg'\n",
    "# im_dim = 128\n",
    "\n",
    "# # Create files\n",
    "# sprite = False\n",
    "# config = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdd872",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def train_data_load(fpath, data_file):\n",
    "#     print('Loading training data')\n",
    "#     # Load saved training tensors file\n",
    "#     train_data = torch.load(fpath + data_file) # (N, W, H, C)\n",
    "\n",
    "#     # Use the training data for sprite creation (Note that this is NOT the entire orthomosaic)\n",
    "#     loader = torch.utils.data.DataLoader(train_data, \n",
    "#                                          batch_size = len(train_data), \n",
    "#                                          shuffle = False)\n",
    "#     dataiter = iter(loader)\n",
    "#     imgs = dataiter.next()\n",
    "\n",
    "#     print('Loading training data complete \\n')\n",
    "    \n",
    "#     return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de7e3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def create_sprite(fpath, data_file):\n",
    "#     print('Creating sprite...')\n",
    "#     imgs = train_data_load(fpath, data_file)\n",
    "    \n",
    "#     # Convert training data torch tensors to numpy (uint8)\n",
    "#     imgs = imgs.cpu().detach().numpy().astype(np.uint8) # (N, W, H, C)\n",
    "    \n",
    "#     num_tiles = imgs.shape[0]\n",
    "#     tile_size = imgs.shape[1]\n",
    "#     sprite_size = int(np.ceil(np.sqrt(num_tiles) * tile_size)) # Tensorflow embedding projector requires square sprite\n",
    "#     print('Total number of tiles: ', num_tiles)\n",
    "#     print('Tile size: {}'.format(tile_size))\n",
    "#     print('Sprite size: {}'.format(sprite_size))\n",
    "\n",
    "#     sprite = Image.new(mode = 'RGB', \n",
    "#                        size = (sprite_size, sprite_size), \n",
    "#                        color = (255, 255, 255)) # White background\n",
    "\n",
    "#     for idx in range(num_tiles):\n",
    "#         h_increment, w_increment = divmod(idx, sprite_size // tile_size) # Returns (0, 0) for idx = 0                                   \n",
    "#         h_loc = tile_size * h_increment\n",
    "#         w_loc = tile_size * w_increment\n",
    "#         img = imgs[idx] # (H, W, C)\n",
    "#         sprite.paste(Image.fromarray(img, mode = 'RGB'), \n",
    "#                      (w_loc, h_loc)) # Loc is upper lefthand corner\n",
    "\n",
    "#         if (idx + 1) % 500 == 0:\n",
    "#             print('Number of tiles processed: ', idx + 1)\n",
    "\n",
    "#     sprite.save(fpath + '\\sprite.jpg') \n",
    "#     print('Creating sprite complete \\n')                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6539040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_proj_config(fpath, embed_file, sprite_file, im_dim):\n",
    "#     print('Creating projector config file...')\n",
    "#     with open(fpath + r'\\Model_MT_Outputs\\projector_config.pbtxt', 'w') as f:\n",
    "#         f.write('embeddings {')\n",
    "#         f.write('\\n')\n",
    "#         f.write('\\ttensor_path: \"{}\"'.format(embed_file))\n",
    "#         f.write('\\n')\n",
    "#         f.write('\\tsprite {')\n",
    "#         f.write('\\n')\n",
    "#         f.write('\\t\\timage_path: \"{}\"'.format(sprite_file))\n",
    "#         f.write('\\n')\n",
    "#         f.write('\\t\\tsingle_image_dim: {}'.format(im_dim))\n",
    "#         f.write('\\n')\n",
    "#         f.write('\\t\\tsingle_image_dim: {}'.format(im_dim))\n",
    "#         f.write('\\n')\n",
    "#         f.write('\\t}')\n",
    "#         f.write('\\n')\n",
    "#         f.write('}')\n",
    "    \n",
    "#     print('Creating projector config file complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6969191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vis_embed(fpath, data_file, embed_file, sprite_file, im_dim = 128, sprite = False, config = False):    \n",
    "#     if sprite:\n",
    "#         create_sprite(fpath, data_file)\n",
    "#     if config:\n",
    "#         write_proj_config(fpath, embed_file, sprite_file, im_dim)\n",
    "#     return spr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb84e79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vis_embed(fpath, data_file, embed_file, sprite_file, im_dim, sprite, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
